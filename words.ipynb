{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Gen Jyuu Gothic Monospace Medium', 'Noto Sans TC', 'Inconsolata'; font-size: 440%; font-weight: 700; text-align: center; color: Plum;\">\n",
    "<br>\n",
    "寫個無聊「遊戲」來練功\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<!-- <div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 180%; text-align: center;\"> -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "// 設定output文字顏色。\ndocument.styleSheets[0].addRule('body', 'color: #87CEFA !important;')\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// 設定output文字顏色。\n",
    "document.styleSheets[0].addRule('body', 'color: #87CEFA !important;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "遊戲規則\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 搜集或隨機產生一個英文單字庫(目前該字庫已有37多萬字)。\n",
    "* 從字庫中取出每一字檢查是否為`ShiftLex`。\n",
    "* 所謂`ShiftLex`，是筆者和ChatGPT討論後創出的新詞，意思是：\n",
    "    * 該字本身是有意義的英文單字。\n",
    "    * 將每一個字母輪流移至(shift)字首，其餘字母順序不變。所有移動後形成的新字都必須為有效英文單字。\n",
    "* `ShiftLex`範例(目前暫未找出4個字母以上的`ShiftLex`)：\n",
    "    * art -> rat -> tar\n",
    "    * tea -> eta -> ate    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "如可「隨機產生」英文單字？\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 簡單：用`random_word` package即可。\n",
    "* `$ pip install random-word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(words) =9\n",
      "{'academe', 'granomerite', 'misbegun', 'modulet', 'grahams', 'howsomever', 'semideltaic', 'haloxylin', 'calcedon'}\n"
     ]
    }
   ],
   "source": [
    "from random_word import RandomWords\n",
    "\n",
    "r = RandomWords()\n",
    "words = set()\n",
    "for i in range(9):\n",
    "    # print(f'{i}', end='\\r')\n",
    "    words.add(r.get_random_word())\n",
    "print(f'{len(words) =}')\n",
    "print(f'{words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "不過這樣隨機產生太慢了！\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 直接到該package的github，將它[整個字庫](https://raw.githubusercontent.com/vaibhavsingh97/random-word/master/random_word/database/words.json)copy出來比較快。\n",
    "* 光用這個字庫筆者嫌不夠(筆者很「龜毛」的)，又從其他網站copy了很多單字，全部轉為小寫後存入`words_raw.dat`檔。\n",
    "* 這個檔案只有最簡單的整理，尚待進一步去蕪存菁，例如過濾重複、刪除過短的字、刪除帶數字或特殊符號者...\n",
    "* 整理的code在下面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372692\r"
     ]
    }
   ],
   "source": [
    "# 單字字庫整理-1：刪除重複及全轉為小寫\n",
    "with open('./words_raw.dat', 'r') as f1:\n",
    "    words = list(set(f1.read().lower().split('\\n')))\n",
    "\n",
    "# 單字字庫整理-2：最少3個字母、字母沒有完全相同、\n",
    "# 且沒有數字和特殊符號者才納入最終字庫。\n",
    "symbols = ('.', ',', '?', '_', '/', '\\\\', '(', ')', '[', ']', '{', '}', '<', '>', '\"', \"'\", '|', ':', ';', '~', '!', '`', '@', '#', '$', '%', '^', '&', '*', '+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', '=', 'þ')\n",
    "with open('./words_final.dat', 'w') as f2:\n",
    "    for index, word in enumerate(words):\n",
    "        leng_word = len(word)\n",
    "        if leng_word >= 3 and word != word[0]*leng_word and not [char for char in word if char in symbols]:\n",
    "            print(f'{index}', end='\\r')\n",
    "            _ = f2.write(f'{word}\\n')\n",
    "            f2.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "資料整理好後，就開始在資料檔逐個檢查了。\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 如何檢查\n",
    "* 使用enchant模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/alex/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk   # .corpus import words\n",
    "\n",
    "nltk.download('words')\n",
    "\"Alex\" in words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\"Taipei\" in words.words()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "# import spellchecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "def check(word):\n",
    "    if word == spell.correction(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "check('Taipei')\n",
    "check('taipei')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_\t\tTaiwan: True\ttaiwan: False\n",
      "en_US\t\tTaiwan: True\ttaiwan: False\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "spellings = ('en_', 'en_US')\n",
    "for spelling in spellings:\n",
    "    d = enchant.Dict(spelling)\n",
    "    word1 = 'Taiwan'\n",
    "    word2 = 'taiwan'\n",
    "    print(f\"{spelling}\\t\\t{word1}: {d.check(word1)}\\t{word2}: {d.check(word2)}\")\n",
    "    # d.check('gray')\n",
    "# d.check(\"Helo\")\n",
    "# d.suggest(\"Helo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 決定應用`en_UK`(英式英文拼法字典)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讀取詞彙檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['en', 'en_AU', 'en_CA', 'en_GB', 'en_US', 'en_ZA']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enchant.dict_exists(\"e_..\")\n",
    "enchant.list_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zyzzyvas'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./words_final.dat', 'r') as f:\n",
    "    words = f.read().split('\\n')\n",
    "    \n",
    "words[-1]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea', 'ups', 'alp', 'rob', 'arm', 'apt', 'int', 'add', 'asp', 'amt', 'opp', 'app', 'own', 'art', 'wee', 'eel', 'opt', '']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# v1: 直白寫  \n",
    "import enchant\n",
    "\n",
    "d = enchant.Dict('en_')\n",
    "shift_lexes = []\n",
    "for word in words:\n",
    "    fitting = True\n",
    "    for index, alphabet in enumerate(word):\n",
    "        print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "        this_rotation = f'{alphabet}{word[:index]}{word[index+1:]}' \n",
    "        if not d.check(this_rotation.lower()):\n",
    "            fitting = False\n",
    "            break\n",
    "    if fitting:\n",
    "       shift_lexes.append(word)\n",
    "        \n",
    "        \n",
    "print(shift_lexes)\n",
    "print(len(shift_lexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbe', 'abbes', 'acme', 'acre', 'acres', 'add', 'adds', 'aids', 'alp', 'alps', 'alts', 'amt', 'angers', 'app', 'appal', 'apps', 'apt', 'arced', 'arcing', 'arm', 'arms', 'arrest', 'art', 'arts', 'asp', 'asps', 'assess', 'avers', 'cares', 'caress', 'cats', 'door', 'doors', 'earring', 'east', 'eats', 'educes', 'eel', 'eels', 'ends', 'eviler', 'greet', 'greets', 'hanks', 'hears', 'hips', 'hist', 'hits', 'huts', 'ides', 'int', 'isms', 'kiss', 'labs', 'lams', 'laps', 'lats', 'lumps', 'manatee', 'manatees', 'mites', 'ones', 'oops', 'opp', 'opt', 'opts', 'ores', 'orts', 'own', 'parses', 'pass', 'pots', 'rapt', 'ribbed', 'ribber', 'ribbers', 'ribbing', 'rob', 'robs', 'steer', 'steers', 'tea', 'ups', 'veer', 'veneer', 'wast', 'watt', 'watts', 'wee', 'weer', 'wees', 'windless']\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# v2: 改為function\n",
    "import enchant\n",
    "def is_valid_shift_lex(lex: str, rotations: int) -> bool:\n",
    "    d = enchant.Dict('en_UK')\n",
    "    fittings = 0\n",
    "    for index, alphebet in enumerate(lex):\n",
    "        this_rotation = f'{alphebet}{lex[:index]}{lex[index+1:]}' \n",
    "        if d.check(this_rotation):\n",
    "            fittings += 1\n",
    "            if fittings >= rotations:\n",
    "                break\n",
    "    return fittings >= rotations or fittings == len(lex)\n",
    "\n",
    "shift_lexes = []\n",
    "for index, word in enumerate(words):\n",
    "    print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "    if is_valid_shift_lex(lex=word, rotations=3):\n",
    "       shift_lexes.append(word)\n",
    "        \n",
    "print(shift_lexes)\n",
    "print(len(shift_lexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea', 'ups', 'alp', 'rob', 'arm', 'apt', 'int', 'add', 'asp', 'amt', 'opp', 'app', 'own', 'art', 'wee', 'eel', 'opt']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# v3: 改為class\n",
    "import enchant\n",
    "\n",
    "class ShiftLex():\n",
    "    def __init__(self):\n",
    "        self.d = enchant.Dict('en_UK')\n",
    "        \n",
    "    def is_valid(self, lex: str, rotations: int) -> bool:\n",
    "        fitting = True\n",
    "        for index, alphabet in enumerate(lex):\n",
    "            this_rotation = f'{alphabet}{lex[:index]}{lex[index+1:]}' \n",
    "            if not self.d.check(this_rotation):\n",
    "                fitting = False\n",
    "                break\n",
    "        return fitting\n",
    "    \n",
    "\n",
    "word = ShiftLex() \n",
    "shift_lexes = []\n",
    "for word in words:\n",
    "    if word.is_valid(lex=word, rotations=3):\n",
    "       shift_lexes.append(word)\n",
    "        \n",
    "print(shift_lexes)\n",
    "print(len(shift_lexes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
