{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Gen Jyuu Gothic Monospace Medium', 'Noto Sans TC', 'Inconsolata'; font-size: 440%; font-weight: 700; text-align: center; color: Plum;\">\n",
    "<br>\n",
    "寫個無聊「遊戲」來練功\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<!-- <div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 180%; text-align: center;\"> -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// 設定output文字顏色。\n",
    "document.styleSheets[0].addRule('body', 'color: #87CEFA !important;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "遊戲規則\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 隨機產生或多方搜集一個英文單字庫(目前該字庫已有37多萬字)。\n",
    "* 從字庫中取出每一字檢查是否為`ShiftLex`。\n",
    "* 所謂`ShiftLex`，是筆者和ChatGPT討論後創出的新詞，意思是：\n",
    "    * 該字本身是有意義的英文單字。\n",
    "    * 將每一個字母輪流移至(shift)字首，其餘字母順序不變。所有移動後形成的新字都必須為有效英文單字。\n",
    "* `ShiftLex`範例(目前暫未找出4個字母以上的`ShiftLex`)：\n",
    "    * art -> rat -> tar\n",
    "    * tea -> eta -> ate  \n",
    "* 夠無聊了吧？依這些功能根本談不上是遊戲，充其量只是練功吧了。倒是可以給比較少寫程式的同學作個step-by-step示範。不過這是急就章下產品，來不及優化，不一定是很好的coding示範。各位請多多給予批評和建議。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "如何「隨機產生」英文單字？\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 簡單：用[random_word package](https://pypi.org/project/Random-Word/)即可。\n",
    "* `$ pip install random-word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(words) = 9\n",
      "{'frontispieced', 'yoke', 'zeks', 'stoked', 'verticomental', 'gems', 'biblists', 'mindlessness', 'smore'}\n"
     ]
    }
   ],
   "source": [
    "from random_word import RandomWords\n",
    "\n",
    "r = RandomWords()\n",
    "words = set()\n",
    "for i in range(9):\n",
    "    words.add(r.get_random_word())\n",
    "print(f'{len(words) = }')\n",
    "print(f'{words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/SyI5hFsS3.png\" height=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "不過這樣隨機產生太慢了！\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 直接到該[package的github](https://github.com/vaibhavsingh97/random-word)，將它[整個字庫](https://raw.githubusercontent.com/vaibhavsingh97/random-word/master/random_word/database/words.json)copy出來比較快。\n",
    "* 不過這個字庫的字偏長且冷僻，筆者又從其他提供單字的網站補充了很幾千個較短的常用單字，經過簡單整理後存入`words_raw.dat`檔。\n",
    "* 這個檔案尚待進一步去蕪存菁，例如過濾重複、刪除過短的字、刪除帶數字或特殊符號者...等等。\n",
    "* 整理的code在下面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372692\r"
     ]
    }
   ],
   "source": [
    "# 單字字庫整理-1：刪除重複及全轉為小寫\n",
    "with open('./words_raw.dat', 'r') as f1:\n",
    "    words = list(set(f1.read().lower().split('\\n')))\n",
    "\n",
    "# 單字字庫整理-2：最少3個字母、字母沒有完全相同、且沒有數字和特殊符號\n",
    "# 者才納入最終字庫。\n",
    "symbols = ('.', ',', '?', '_', '/', '\\\\', '(', ')', '[', ']', '{', '}', '<', '>', '\"', \"'\", '|', ':', ';', '~', '!', '`', '@', '#', '$', '%', '^', '&', '*', '+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', '=', 'þ')\n",
    "with open('./words_final.dat', 'w') as f2:\n",
    "    for index, word in enumerate(words):\n",
    "        leng_word = len(word)\n",
    "        if leng_word >= 3 and word != word[0]*leng_word and not [char for char in word if char in symbols]:\n",
    "            print(f'{index}', end='\\r')\n",
    "            _ = f2.write(f'{word}\\n')\n",
    "            f2.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/HJsUHmqEn.jpg\" height=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "資料整理好後，正式幹活...\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 目前面臨的問題是：如何得知某個字母的組合是「有效的英文單字」？ChatGPT API等AI工具一定可以搞定，不過殺雞好像不必用牛刀，而且得付token費。暫不考慮。\n",
    "* 稍為搜尋一下，找到以下3套Python的模組，大扺可滿足需求：\n",
    "    1. enchant\n",
    "    2. nltk\n",
    "    3. spellchecker\n",
    "* 也許還有別的更好用模組，待日後很有空時再找好了。目前先試用這3套，看效果如何。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkSalmon; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 250%; font-weight: 700;\">\n",
    "1. enchant\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* `$ pip install pyenchant`\n",
    "* [PyEnchant Introdution](https://pyenchant.github.io/pyenchant/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en', 'en_AU', 'en_CA', 'en_GB', 'en_US', 'en_ZA']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "# 使用前\n",
    "enchant.list_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/r1CGkKF1p.png\" height=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_US\tcenter: True\tcentre: False\n",
      "en_\tcenter: True\tcentre: True\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "spellings = ('en_US', 'en_')   # 'en_'好像是英美spelling通吃。\n",
    "for spelling in spellings:\n",
    "    d = enchant.Dict(spelling)   # 先設定使用哪種「英文」\n",
    "    word1 = 'center'   # American spelling\n",
    "    word2 = 'centre'   # British spelling\n",
    "    print(f\"{spelling}\\t{word1}: {d.check(word1)}\\t{word2}: {d.check(word2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amblyope', 'capably', 'yorlin', 'eloiners', 'atomiferous']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['ascidioida', 'disappear', 'salutarily', 'reflash', 'chlorophoenicite']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./words_final.dat', 'r') as f:\n",
    "    words = f.read().split('\\n')\n",
    "\n",
    "words[:5]\n",
    "words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asp', 'art', 'ups', 'eel', 'opp', 'own', 'app', 'wee', 'tea', 'rob', 'add', 'opt', 'amt', 'alp', 'arm', 'int', 'apt']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# v1: 直白寫\n",
    "import enchant\n",
    "\n",
    "d = enchant.Dict('en_')\n",
    "shift_lexicons = []\n",
    "for word in words:\n",
    "    fitting = True\n",
    "    for index, alphabet in enumerate(word):\n",
    "        print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "        this_rotation = f'{alphabet}{word[:index]}{word[index+1:]}'\n",
    "        if not d.check(this_rotation.lower()):\n",
    "            fitting = False\n",
    "            break\n",
    "    if fitting:\n",
    "       shift_lexicons.append(word)\n",
    "\n",
    "\n",
    "print(shift_lexicons)\n",
    "print(len(shift_lexicons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asp', 'art', 'ups', 'eel', 'opp', 'own', 'app', 'wee', 'tea', 'rob', 'add', 'opt', 'amt', 'alp', 'arm', 'int', 'apt']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# v2: 改為function，同時加上「最少次數」，讓較多的字符合標準。\n",
    "import enchant\n",
    "def is_valid_shift_lex(lexicon: str, min_fittings: int) -> bool:\n",
    "    d = enchant.Dict('en_')\n",
    "    fittings = 0\n",
    "    for index, alphebet in enumerate(lexicon):\n",
    "        this_rotation = f'{alphebet}{lexicon[:index]}{lexicon[index+1:]}'\n",
    "        if d.check(this_rotation):  # 是有效單字\n",
    "            fittings += 1\n",
    "            if fittings == min_fittings:\n",
    "                break\n",
    "    return fittings == min_fittings or fittings == len(lexicon)\n",
    "\n",
    "shift_lexicons = []\n",
    "for index, word in enumerate(words):\n",
    "    print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "    if is_valid_shift_lex(lexicon=word, min_fittings=4):\n",
    "       shift_lexicons.append(word)\n",
    "\n",
    "print(shift_lexicons)\n",
    "print(len(shift_lexicons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acres\n",
      "cares\n",
      "races\n"
     ]
    }
   ],
   "source": [
    "# 印證某單是否符合min_fittings門檻。\n",
    "import enchant\n",
    "def is_valid_shift_lex(lexicon: str, min_fittings: int) -> bool:\n",
    "    d = enchant.Dict('en_')\n",
    "    fittings = 0\n",
    "    for index, alphebet in enumerate(lexicon):\n",
    "        this_rotation = f'{alphebet}{lexicon[:index]}{lexicon[index+1:]}'\n",
    "        if d.check(this_rotation):\n",
    "            print(this_rotation)\n",
    "            fittings += 1\n",
    "            if fittings == min_fittings:\n",
    "                break\n",
    "    return fittings == min_fittings or fittings == len(lexicon)\n",
    "\n",
    "word = 'acres'\n",
    "_ = is_valid_shift_lex(lexicon=word, min_fittings=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asp', 'veneer', 'rapt', 'acme', 'art', 'manatee', 'acres', 'parses', 'ones', 'appal', 'ups', 'steers', 'eel', 'weer', 'cats', 'wast', 'angers', 'assess', 'eels', 'apps', 'eviler', 'hits', 'watt', 'opp', 'alts', 'arced', 'arrest', 'own', 'mites', 'lumps', 'opts', 'abbe', 'app', 'arcing', 'hips', 'wee', 'tea', 'hears', 'ribbers', 'acre', 'ribbed', 'rob', 'add', 'manatees', 'opt', 'arts', 'abbes', 'alps', 'asps', 'ribbing', 'steer', 'orts', 'watts', 'door', 'east', 'caress', 'aids', 'eats', 'greet', 'hanks', 'cares', 'amt', 'robs', 'arms', 'adds', 'pass', 'ores', 'labs', 'kiss', 'greets', 'laps', 'lats', 'veer', 'avers', 'isms', 'educes', 'huts', 'oops', 'ides', 'earring', 'alp', 'ribber', 'arm', 'windless', 'wees', 'hist', 'ends', 'int', 'apt', 'pots', 'lams', 'doors']\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# v3: 改為class\n",
    "import enchant\n",
    "\n",
    "class ShiftLex():\n",
    "    def __init__(self):\n",
    "        self.d = enchant.Dict('en_')\n",
    "\n",
    "    def is_valid(self, lexicon: str, min_fittings: int) -> bool:\n",
    "        d = enchant.Dict('en_')\n",
    "        fittings = 0\n",
    "        for index, alphebet in enumerate(lexicon):\n",
    "            this_rotation = f'{alphebet}{lexicon[:index]}{lexicon[index+1:]}'\n",
    "            if d.check(this_rotation):\n",
    "                fittings += 1\n",
    "                if fittings == min_fittings:\n",
    "                    break\n",
    "        return fittings == min_fittings or fittings == len(lexicon)\n",
    "\n",
    "\n",
    "lexicon = ShiftLex()\n",
    "shift_lexicons = []\n",
    "for index, word in enumerate(words):\n",
    "    print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "    if lexicon.is_valid(lexicon=word, min_fittings=3):\n",
    "       shift_lexicons.append(word)\n",
    "\n",
    "print(shift_lexicons)\n",
    "print(len(shift_lexicons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkSalmon; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 250%; font-weight: 700;\">\n",
    "2. nltk(Natural Language Toolkit)\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* `$ pip install nltk`\n",
    "* [nltk documentation](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'language' in words.words() = True\n",
      "'langage' in words.words() = False\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "print(f\"{'language' in words.words() = }\")\n",
    "print(f\"{'langage' in words.words() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkSalmon; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 250%; font-weight: 700;\">\n",
    "3. spellchecker\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* `$ pip install pyspellchecker`\n",
    "* [spellcheckertk documentation](https://pyspellchecker.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: True\n",
      "langage: False\n",
      "alex\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "print(f\"{'language'}: {'language' == spell.correction('language')}\")\n",
    "print(f\"{'langage'}: {'langage' == spell.correction('langage')}\")\n",
    "\n",
    "print(f\"{spell.correction('alexs')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://i.imgur.com/ho0NZ9y.png\" height=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = [('Catilexa', 'catilexa'), ('Taipei', 'taipei'), ('Europe', 'europe'), ('Microsoft', 'microsoft'), ('Linux', 'linux'), ('NATO', 'nato'), ('Christmas', 'christmas')]\n",
    "\n",
    "leng_lex = 9; leng_result = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catilexa : False       catilexa : False\n",
      "Taipei   : True        taipei   : False\n",
      "Europe   : True        europe   : False\n",
      "Microsoft: True        microsoft: False\n",
      "Linux    : True        linux    : False\n",
      "NATO     : True        nato     : False\n",
      "Christmas: True        christmas: False\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "d = enchant.Dict('en_')   # 先設定使用哪種「英文」\n",
    "for lexicon in lexicons:\n",
    "    print(f\"{lexicon[0]:{leng_lex}}: {str(d.check(lexicon[0])):{leng_result}}{lexicon[1]:{leng_lex}}: {d.check(lexicon[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catilexa : False       catilexa : False\n",
      "Taipei   : False       taipei   : False\n",
      "Europe   : False       europe   : False\n",
      "Microsoft: False       microsoft: False\n",
      "Linux    : False       linux    : False\n",
      "NATO     : False       nato     : False\n",
      "Christmas: True        christmas: True\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "for lexicon in lexicons:\n",
    "    print(f\"{lexicon[0]:{leng_lex}}: {str(lexicon[0] in words.words()):{leng_result}}{lexicon[1]:{leng_lex}}: {lexicon[0] in words.words()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catilexa : False       catilexa : False\n",
      "Taipei   : True        taipei   : True\n",
      "Europe   : True        europe   : True\n",
      "Microsoft: False       microsoft: False\n",
      "Linux    : False       linux    : False\n",
      "NATO     : True        nato     : True\n",
      "Christmas: True        christmas: True\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "for lexicon in lexicons:\n",
    "    print(f\"{lexicon[0]:{leng_lex}}: {str(lexicon[0] == spell.correction(lexicon[0])):{leng_result}}{lexicon[1]:{leng_lex}}: {lexicon[1] == spell.correction(lexicon[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "結論\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 本「遊戲」非常無趣，不過可借此練一下基本功。\n",
    "* 如果不用ChatGPT等AI方法，要判斷英文單字，暫時找不到一個非常理想的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/r1mSyb9Ja.png\" width=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2230'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"\"\"{f'''{f'{f\"{1+1}\"*2}'+'3'}'''+'0'}\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
