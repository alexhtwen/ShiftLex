{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Gen Jyuu Gothic Monospace Medium', 'Noto Sans TC', 'Inconsolata'; font-size: 440%; font-weight: 700; text-align: center; color: Plum;\">\n",
    "<br>\n",
    "寫個無聊「遊戲」來練功\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<!-- <div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 180%; text-align: center;\"> -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "// 設定output文字顏色。\ndocument.styleSheets[0].addRule('body', 'color: #87CEFA !important;')\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// 設定output文字顏色。\n",
    "document.styleSheets[0].addRule('body', 'color: #87CEFA !important;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "遊戲規則\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 搜集或隨機產生一個英文單字庫(目前該字庫已有37多萬字)。\n",
    "* 從字庫中取出每一字檢查是否為`ShiftLex`。\n",
    "* 所謂`ShiftLex`，是筆者和ChatGPT討論後創出的新詞，意思是：\n",
    "    * 該字本身是有意義的英文單字。\n",
    "    * 將每一個字母輪流移至(shift)字首，其餘字母順序不變。所有移動後形成的新字都必須為有效英文單字。\n",
    "* `ShiftLex`範例(目前暫未找出4個字母以上的`ShiftLex`)：\n",
    "    * art -> rat -> tar\n",
    "    * tea -> eta -> ate  \n",
    "* 夠無聊了吧？依這些功能根本談不上是遊戲，充其量只是練功吧了。倒是可以給比較少寫程式的同學作個step-by-step示範。不過這是急就章下產品，來不及優化，不一定是很好的coding示範。各位請多多給予批評和建議。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "如何「隨機產生」英文單字？\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 簡單：用[random_word package](https://pypi.org/project/Random-Word/)即可。\n",
    "* `$ pip install random-word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(words) =9\n",
      "{'swird', 'catalyzers', 'rudolphine', 'quadricone', 'countercultural', 'surgerize', 'serpentinize', 'amyloplastid', 'almanac'}\n"
     ]
    }
   ],
   "source": [
    "from random_word import RandomWords\n",
    "\n",
    "r = RandomWords()\n",
    "words = set()\n",
    "for i in range(9):\n",
    "    # print(f'{i}', end='\\r')\n",
    "    words.add(r.get_random_word())\n",
    "print(f'{len(words) =}')\n",
    "print(f'{words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/SyI5hFsS3.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "不過這樣隨機產生太慢了！\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 直接到該[package的github](https://github.com/vaibhavsingh97/random-word)，將它[整個字庫](https://raw.githubusercontent.com/vaibhavsingh97/random-word/master/random_word/database/words.json)copy出來比較快。\n",
    "* 不過這個字庫的字偏長且冷僻，筆者又從其他提供單字的網站補充了很幾千個較短的常用單字，經過簡單整理後存入`words_raw.dat`檔。\n",
    "* 這個檔案尚待進一步去蕪存菁，例如過濾重複、刪除過短的字、刪除帶數字或特殊符號者...等等。\n",
    "* 整理的code在下面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372692\r"
     ]
    }
   ],
   "source": [
    "# 單字字庫整理-1：刪除重複及全轉為小寫\n",
    "with open('./words_raw.dat', 'r') as f1:\n",
    "    words = list(set(f1.read().lower().split('\\n')))\n",
    "\n",
    "# 單字字庫整理-2：最少3個字母、字母沒有完全相同、且沒有數字和特殊符號\n",
    "# 者才納入最終字庫。\n",
    "symbols = ('.', ',', '?', '_', '/', '\\\\', '(', ')', '[', ']', '{', '}', '<', '>', '\"', \"'\", '|', ':', ';', '~', '!', '`', '@', '#', '$', '%', '^', '&', '*', '+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', '=', 'þ')\n",
    "with open('./words_final.dat', 'w') as f2:\n",
    "    for index, word in enumerate(words):\n",
    "        leng_word = len(word)\n",
    "        if leng_word >= 3 and word != word[0]*leng_word and not [char for char in word if char in symbols]:\n",
    "            print(f'{index}', end='\\r')\n",
    "            _ = f2.write(f'{word}\\n')\n",
    "            f2.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/HJsUHmqEn.jpg\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "資料整理好後，正式幹活...\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 目前面臨的問題是：如何得知某個字母的組合是「有效的英文單字」？ChatGPT API等AI工具一定可以搞定，不過殺雞好像不必用牛刀，而且得付token費。暫不考慮。\n",
    "* 稍為搜尋一下，找到以下3套Python的模組，大扺可滿足需求：\n",
    "    1. enchant\n",
    "    2. nltk\n",
    "    3. spellchecker\n",
    "* 也許還有別的更好用模組，待日後很有空時再找好了。目前先試用這3套，看效果如何。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkSalmon; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 250%; font-weight: 700;\">\n",
    "1. enchant\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* `$ pip install pyenchant`\n",
    "* [PyEnchant Introdution](https://pyenchant.github.io/pyenchant/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en', 'en_AU', 'en_CA', 'en_GB', 'en_US', 'en_ZA']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "# 使用前\n",
    "enchant.list_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://hackmd.io/_uploads/r1CGkKF1p.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_US\tcenter: True\t??????: False\n",
      "en_\tcenter: True\t??????: False\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "spellings = ('en_US', 'en_')   # 'en_'好像是英美spelling通吃。\n",
    "for spelling in spellings:\n",
    "    d = enchant.Dict(spelling)   # 先設定使用哪種「英文」\n",
    "    word1 = 'center'   # American spelling\n",
    "    word2 = '??????'   # British spelling\n",
    "    print(f\"{spelling}\\t{word1}: {d.check(word1)}\\t{word2}: {d.check(word2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balsamodendron', 'undershorts', 'stoures', 'perfecter', 'unnooked']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['sporogenesis', 'tetanilla', 'cismontane', 'breastpiece', 'geostrategic']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./words_final.dat', 'r') as f:\n",
    "    words = f.read().split('\\n')\n",
    "\n",
    "words[:5]\n",
    "words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea', 'ups', 'alp', 'rob', 'arm', 'apt', 'int', 'add', 'asp', 'amt', 'opp', 'app', 'own', 'art', 'wee', 'eel', 'opt', '']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# v1: 直白寫\n",
    "import enchant\n",
    "\n",
    "d = enchant.Dict('en_')\n",
    "shift_lexes = []\n",
    "for word in words:\n",
    "    fitting = True\n",
    "    for index, alphabet in enumerate(word):\n",
    "        print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "        this_rotation = f'{alphabet}{word[:index]}{word[index+1:]}'\n",
    "        if not d.check(this_rotation.lower()):\n",
    "            fitting = False\n",
    "            break\n",
    "    if fitting:\n",
    "       shift_lexes.append(word)\n",
    "\n",
    "\n",
    "print(shift_lexes)\n",
    "print(len(shift_lexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arts', 'huts', 'laps', 'adds', 'earring', 'wees', 'appal', 'ribbed', 'assess', 'opts', 'doors', 'opt', 'lumps', 'ones', 'pass', 'arms', 'parses', 'asps', 'hits', 'opp', 'mites', 'arcing', 'ups', 'cares', 'veneer', 'labs', 'avers', 'arm', 'watt', 'caress', 'ribbers', 'manatee', 'educes', 'abbes', 'eels', 'apps', 'orts', 'apt', 'eel', 'ribber', 'manatees', 'robs', 'oops', 'isms', 'acme', 'asp', 'steer', 'hanks', 'eviler', 'greet', 'angers', 'door', 'windless', 'rapt', 'int', 'eats', 'rob', 'ends', 'wee', 'app', 'steers', 'east', 'acres', 'acre', 'greets', 'alps', 'alp', 'ides', 'ores', 'pots', 'watts', 'own', 'weer', 'amt', 'aids', 'tea', 'ribbing', 'kiss', 'art', 'wast', 'hist', 'hears', 'lams', 'veer', 'add', 'cats', 'arrest', 'lats', 'arced', 'abbe', 'alts', 'hips']\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# v2: 改為function，同時加上「最少次數」，讓較多的字符合標準。\n",
    "import enchant\n",
    "def is_valid_shift_lex(lex: str, rotations: int) -> bool:\n",
    "    d = enchant.Dict('en_')\n",
    "    fittings = 0\n",
    "    for index, alphebet in enumerate(lex):\n",
    "        this_rotation = f'{alphebet}{lex[:index]}{lex[index+1:]}'\n",
    "        if d.check(this_rotation):\n",
    "            fittings += 1\n",
    "            if fittings >= rotations:\n",
    "                break\n",
    "    return fittings >= rotations or fittings == len(lex)\n",
    "\n",
    "shift_lexes = []\n",
    "for index, word in enumerate(words):\n",
    "    print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "    if is_valid_shift_lex(lex=word, rotations=3):\n",
    "       shift_lexes.append(word)\n",
    "\n",
    "print(shift_lexes)\n",
    "print(len(shift_lexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acres\n",
      "cares\n",
      "races\n"
     ]
    }
   ],
   "source": [
    "# v2: 改為function，同時加上「最少次數」，讓較多的字符合標準。\n",
    "import enchant\n",
    "def is_valid_shift_lex(lex: str, rotations: int) -> bool:\n",
    "    d = enchant.Dict('en_')\n",
    "    fittings = 0\n",
    "    for index, alphebet in enumerate(lex):\n",
    "        this_rotation = f'{alphebet}{lex[:index]}{lex[index+1:]}'\n",
    "        if d.check(this_rotation):\n",
    "            print(this_rotation)\n",
    "            fittings += 1\n",
    "            if fittings >= rotations:\n",
    "                break\n",
    "    return fittings >= rotations or fittings == len(lex)\n",
    "\n",
    "word = 'acres'\n",
    "_ = is_valid_shift_lex(lex=word, rotations=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arts', 'huts', 'laps', 'adds', 'earring', 'wees', 'appal', 'ribbed', 'assess', 'opts', 'doors', 'opt', 'lumps', 'ones', 'pass', 'arms', 'parses', 'asps', 'hits', 'opp', 'mites', 'arcing', 'ups', 'cares', 'veneer', 'labs', 'avers', 'arm', 'watt', 'caress', 'ribbers', 'manatee', 'educes', 'abbes', 'eels', 'apps', 'orts', 'apt', 'eel', 'ribber', 'manatees', 'robs', 'oops', 'isms', 'acme', 'asp', 'steer', 'hanks', 'eviler', 'greet', 'angers', 'door', 'windless', 'rapt', 'int', 'eats', 'rob', 'ends', 'wee', 'app', 'steers', 'east', 'acres', 'acre', 'greets', 'alps', 'alp', 'ides', 'ores', 'pots', 'watts', 'own', 'weer', 'amt', 'aids', 'tea', 'ribbing', 'kiss', 'art', 'wast', 'hist', 'hears', 'lams', 'veer', 'add', 'cats', 'arrest', 'lats', 'arced', 'abbe', 'alts', 'hips']\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# v3: 改為class\n",
    "import enchant\n",
    "\n",
    "class ShiftLex():\n",
    "    def __init__(self):\n",
    "        self.d = enchant.Dict('en_')\n",
    "\n",
    "    def is_valid(self, lex: str, rotations: int) -> bool:\n",
    "        d = enchant.Dict('en_')\n",
    "        fittings = 0\n",
    "        for index, alphebet in enumerate(lex):\n",
    "            this_rotation = f'{alphebet}{lex[:index]}{lex[index+1:]}'\n",
    "            if d.check(this_rotation):\n",
    "                fittings += 1\n",
    "                if fittings >= rotations:\n",
    "                    break\n",
    "        return fittings >= rotations or fittings == len(lex)\n",
    "\n",
    "\n",
    "lex = ShiftLex()\n",
    "shift_lexes = []\n",
    "for index, word in enumerate(words):\n",
    "    print(f'{index:,} / {len(words):,}', end='\\r')\n",
    "    if lex.is_valid(lex=word, rotations=3):\n",
    "       shift_lexes.append(word)\n",
    "\n",
    "print(shift_lexes)\n",
    "print(len(shift_lexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkSalmon; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 250%; font-weight: 700;\">\n",
    "2. nltk(Natural Language Toolkit)\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* `$ pip install nltk`\n",
    "* [nltk documentation](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'language' in words.words() = True\n",
      "'langage' in words.words() = False\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "print(f\"{'language' in words.words() = }\")\n",
    "print(f\"{'langage' in words.words() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkSalmon; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 250%; font-weight: 700;\">\n",
    "3. spellchecker\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* `$ pip install pyspellchecker`\n",
    "* [spellcheckertk documentation](https://pyspellchecker.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: True\n",
      "langage: False\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "print(f\"{'language'}: {'language' == spell.correction('language')}\")\n",
    "print(f\"{'langage'}: {'langage' == spell.correction('langage')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"https://i.imgur.com/ho0NZ9y.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = [('Alex', 'alex'), ('Taipei', 'taipei'), ('Europe', 'europe'), ('Microsoft', 'microsoft'), ('Linux', 'linux'), ('NATO', 'nato'), ('Christmas', 'christmas')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex: True\t\talex: False\n",
      "Taipei: True\t\ttaipei: False\n",
      "Europe: True\t\teurope: False\n",
      "Microsoft: True\t\tmicrosoft: False\n",
      "Linux: True\t\tlinux: False\n",
      "NATO: True\t\tnato: False\n",
      "Christmas: True\t\tchristmas: False\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "d = enchant.Dict('en_')   # 先設定使用哪種「英文」\n",
    "for lex in lexicons:\n",
    "    print(f\"{lex[0]}: {d.check(lex[0])}\\t\\t{lex[1]}: {d.check(lex[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex: True\t\talex: True\n",
      "Taipei: False\t\ttaipei: False\n",
      "Europe: False\t\teurope: False\n",
      "Microsoft: False\t\tmicrosoft: False\n",
      "Linux: False\t\tlinux: False\n",
      "NATO: False\t\tnato: False\n",
      "Christmas: True\t\tchristmas: True\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "for lex in lexicons:\n",
    "    print(f\"{lex[0]}: {lex[0] in words.words()}\\t\\t{lex[1]}: {lex[0] in words.words()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex: True\t\talex: True\n",
      "Taipei: True\t\ttaipei: True\n",
      "Europe: True\t\teurope: True\n",
      "Microsoft: False\t\tmicrosoft: False\n",
      "Linux: False\t\tlinux: False\n",
      "NATO: True\t\tnato: True\n",
      "Christmas: True\t\tchristmas: True\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "for lex in lexicons:\n",
    "    print(f\"{lex[0]}: {lex[0] == spell.correction(lex[0])}\\t\\t{lex[1]}: {lex[1] == spell.correction(lex[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: SteelBlue; font-family: 'Ubuntu Mono', 'Inconsolata', 'Noto Sans TC'; font-size: 300%; font-weight: 700;\">\n",
    "結論\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Inconsolata', 'Noto Sans TC'; font-size: 135%; color: Gainsboro\">\n",
    "\n",
    "* 本「遊戲」非常無趣，不過可借此練一下基本功。\n",
    "* 如果不用ChatGPT等AI方法，要判斷英文單字，暫時找不到一個非常理想的工具。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
